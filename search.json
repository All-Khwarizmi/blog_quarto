[
  {
    "objectID": "dico-series.html",
    "href": "dico-series.html",
    "title": "Dico, le dictionnaire automatique qui éduque les élèves à l’utiliser judicieusement",
    "section": "",
    "text": "Dico, première version\n\n\n\n\n\n\n\n\n\n\n\nJan 21, 2024\n\n\n3 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/road_map/index.html",
    "href": "posts/road_map/index.html",
    "title": "L’Education 2.0",
    "section": "",
    "text": "Quiconque essaye d’apprendre une langue, a pu se rendre compte que malgré la multitude d’outils disponibles, il n’existe pas de méthode intégrale (ce terme est utilisé dans le sens de “qui contient tout ce qui est nécessaire”) pour apprendre une langue, surtout pour un public adolescent. En effet, les méthodes d’apprentissage des langues sont souvent trop scolaires et ne permettent pas de développer les compétences nécessaires pour communiquer dans la langue cible. De plus, les outils disponibles sur internet sont souvent trop éparpillés, ne permettant pas de suivre une progression logique, et/ou incomplètes, c’est-à-dire qu’elles ne permettent de travailler que certaines des compétences linguistiques.\n\n\n\n\nLa méthode intégrale est une méthode d’apprentissage des langues qui a été développée par John and Evelyn White en 1963. Elle est basée sur le principe que l’apprentissage d’une langue doit se faire de manière naturelle, comme l’apprentissage de la langue maternelle. Elle se base sur 4 compétences linguistiques : la compréhension orale, la compréhension écrite, l’expression orale et l’expression écrite.\n\n\n\nEn tant que professeur de langue mon approche est de développer les 4 compétences linguistiques de manière équilibrée, intuitive et amusante. Cependant, ma pratique enseignante m’a montré que les élèves ont souvent des difficultés d’ordre méthodologique. En effet, ils ne savent pas comment travailler efficacement et comment utiliser les outils à leur disposition.\nDès lors, il devient primordial de leur apprendre à apprendre. C’est pourquoi, j’ai décidé de développer une méthode intégrale qui permettra aux élèves de travailler de manière autonome et efficace. Cette méthode est basée sur 3 piliers : &gt; la motivation, la méthodologie et la mémorisation.\nSe pose alors la question de savoir comment développer ces 3 piliers. Pour répondre à cette question, j’ai dû explorer les sciences cognitives et les neurosciences afin de comprendre comment fonctionne le cerveau humain, l’informatique pour être capable de créer les outils nécessaires, et l’IA afin de créer un “double” du professeur à même de guider l’élève dans son apprentissage.\n\n\n\n\nIl s’agit-là d’un projet titanesque. J’ai longtemps alterné entre différents projets cherchant à développer chacun des piliers. Cependant, j’ai fini par me rendre compte que j’avais besoin d’une architecture conceptuelle qui me permettrait de développer les 3 piliers de manière simultanée.\n\n\n\n\nJ’ai d’abord été bleuffé par ChatGPT.\n\nChatGPT est un modèle de génération de texte basé sur l’architecture Transformer. Ce modèle est capable de générer du texte à partir d’un texte d’entrée. Il est capable de générer des textes cohérents et pertinents.\n\nJ’ai alors eu l’idée de créer un chatbot capable de guider l’élève dans son apprentissage. Cependant, je me suis vite rendu compte qu’il allait falloir orchestrer plusieurs LLM ou agents pour pouvoir couvrir l’ensemble des compétences linguistiques et methodologiques.\n\n\n\n\nLes Systèmes Tutoriels Intelligents (STI) représentent une avancée majeure dans le domaine de l’éducation assistée par la technologie. Ces systèmes, qui allient les principes de l’intelligence artificielle à la pédagogie, sont conçus pour offrir une expérience d’apprentissage personnalisée, s’adaptant au rythme et aux besoins spécifiques de chaque apprenant.\n\nLes STI sont des programmes informatiques qui utilisent des techniques d’IA pour simuler l’interaction personnalisée entre un enseignant et un élève. Dans une vision traditionnelle, un STI se compose de quatre modules principaux : - le modèle du domaine, qui contient les connaissances à enseigner - le modèle pédagogique, qui définit la manière d’enseigner - le modèle de l’apprenant, qui s’adapte aux caractéristiques individuelles de l’élève - le modèle de l’interface, qui facilite l’interaction entre l’élève et le système.\nCes composants travaillent de concert pour créer un environnement d’apprentissage interactif et adaptatif, permettant à l’élève de progresser à son propre rythme et selon son style d’apprentissage unique.\n\n\n\nL’application des STI à l’apprentissage des langues ouvre des horizons passionnants. Dans un STI dédié à l’apprentissage d’une langue, le modèle du domaine intégrerait non seulement la grammaire et le vocabulaire, mais aussi des éléments culturels et contextuels essentiels à la maîtrise de la langue. Le modèle pédagogique pourrait inclure des méthodes telles que l’immersion linguistique, les dialogues interactifs, et les jeux de rôle. Le modèle de l’apprenant suivrait les progrès de l’élève en compréhension orale et écrite, en expression, et en grammaire, s’ajustant pour cibler les domaines nécessitant une attention supplémentaire. Enfin, l’interface serait conçue pour encourager l’engagement et la pratique active, avec des fonctionnalités comme la reconnaissance vocale pour la pratique de la prononciation et des simulations de conversation.\nEn intégrant ces éléments, un STI pour l’apprentissage des langues ne se contente pas de transmettre des connaissances ; il crée un environnement riche et interactif où l’apprenant peut s’immerger dans la langue et la culture, favorisant ainsi une expérience d’apprentissage plus naturelle et efficace.\n\n\n\n\n\n\nLes modèles génératifs, tels que les grands modèles de langage basés sur l’intelligence artificielle, offrent une capacité de génération de contenu dynamique et contextuel. Dans un STI pour l’apprentissage des langues, ces modèles peuvent produire des dialogues réalistes, des exercices de compréhension, ou même des scénarios interactifs. Cette capacité de génération de contenu enrichit le modèle du domaine en fournissant une variété de matériel éducatif, allant des phrases simples aux dialogues complexes, adaptés au niveau de compétence de l’élève.\n\n\n\nLes modèles génératifs permettent une personnalisation plus profonde dans le modèle de l’apprenant. En analysant les réponses et les interactions de l’élève, le système peut ajuster dynamiquement le contenu pour cibler les zones de faiblesse, offrir des défis appropriés, et encourager la progression. De plus, ces modèles peuvent simuler des conversations réelles, permettant aux élèves de pratiquer la langue dans un contexte plus naturel et engageant.\n\n\n\nDans le modèle pédagogique, les modèles génératifs contribuent à fournir un retour d’information instantané et contextualisé. Par exemple, après un exercice de dialogue, le système peut offrir des corrections, des suggestions et des explications spécifiques, aidant l’apprenant à comprendre et à corriger ses erreurs en temps réel.\n\n\n\nEnfin, dans le modèle de l’interface, l’intégration de l’IA et des modèles génératifs peut rendre l’interaction avec le système plus intuitive et naturelle. Des fonctionnalités comme la reconnaissance vocale avancée et la génération de réponses en langue naturelle rendent l’apprentissage plus immersif et similaire à une interaction humaine.\nEn somme, l’intégration des modèles génératifs dans les STI pour l’apprentissage des langues transforme non seulement la manière dont le contenu éducatif est présenté, mais aussi la façon dont les élèves interagissent avec ce contenu, rendant l’expérience d’apprentissage plus riche, personnalisée et efficace."
  },
  {
    "objectID": "posts/road_map/index.html#la-méthode-intégrale",
    "href": "posts/road_map/index.html#la-méthode-intégrale",
    "title": "L’Education 2.0",
    "section": "",
    "text": "La méthode intégrale est une méthode d’apprentissage des langues qui a été développée par John and Evelyn White en 1963. Elle est basée sur le principe que l’apprentissage d’une langue doit se faire de manière naturelle, comme l’apprentissage de la langue maternelle. Elle se base sur 4 compétences linguistiques : la compréhension orale, la compréhension écrite, l’expression orale et l’expression écrite.\n\n\n\nEn tant que professeur de langue mon approche est de développer les 4 compétences linguistiques de manière équilibrée, intuitive et amusante. Cependant, ma pratique enseignante m’a montré que les élèves ont souvent des difficultés d’ordre méthodologique. En effet, ils ne savent pas comment travailler efficacement et comment utiliser les outils à leur disposition.\nDès lors, il devient primordial de leur apprendre à apprendre. C’est pourquoi, j’ai décidé de développer une méthode intégrale qui permettra aux élèves de travailler de manière autonome et efficace. Cette méthode est basée sur 3 piliers : &gt; la motivation, la méthodologie et la mémorisation.\nSe pose alors la question de savoir comment développer ces 3 piliers. Pour répondre à cette question, j’ai dû explorer les sciences cognitives et les neurosciences afin de comprendre comment fonctionne le cerveau humain, l’informatique pour être capable de créer les outils nécessaires, et l’IA afin de créer un “double” du professeur à même de guider l’élève dans son apprentissage."
  },
  {
    "objectID": "posts/road_map/index.html#architecture-conceptuelle",
    "href": "posts/road_map/index.html#architecture-conceptuelle",
    "title": "L’Education 2.0",
    "section": "",
    "text": "Il s’agit-là d’un projet titanesque. J’ai longtemps alterné entre différents projets cherchant à développer chacun des piliers. Cependant, j’ai fini par me rendre compte que j’avais besoin d’une architecture conceptuelle qui me permettrait de développer les 3 piliers de manière simultanée.\n\n\n\n\nJ’ai d’abord été bleuffé par ChatGPT.\n\nChatGPT est un modèle de génération de texte basé sur l’architecture Transformer. Ce modèle est capable de générer du texte à partir d’un texte d’entrée. Il est capable de générer des textes cohérents et pertinents.\n\nJ’ai alors eu l’idée de créer un chatbot capable de guider l’élève dans son apprentissage. Cependant, je me suis vite rendu compte qu’il allait falloir orchestrer plusieurs LLM ou agents pour pouvoir couvrir l’ensemble des compétences linguistiques et methodologiques.\n\n\n\n\nLes Systèmes Tutoriels Intelligents (STI) représentent une avancée majeure dans le domaine de l’éducation assistée par la technologie. Ces systèmes, qui allient les principes de l’intelligence artificielle à la pédagogie, sont conçus pour offrir une expérience d’apprentissage personnalisée, s’adaptant au rythme et aux besoins spécifiques de chaque apprenant.\n\nLes STI sont des programmes informatiques qui utilisent des techniques d’IA pour simuler l’interaction personnalisée entre un enseignant et un élève. Dans une vision traditionnelle, un STI se compose de quatre modules principaux : - le modèle du domaine, qui contient les connaissances à enseigner - le modèle pédagogique, qui définit la manière d’enseigner - le modèle de l’apprenant, qui s’adapte aux caractéristiques individuelles de l’élève - le modèle de l’interface, qui facilite l’interaction entre l’élève et le système.\nCes composants travaillent de concert pour créer un environnement d’apprentissage interactif et adaptatif, permettant à l’élève de progresser à son propre rythme et selon son style d’apprentissage unique.\n\n\n\nL’application des STI à l’apprentissage des langues ouvre des horizons passionnants. Dans un STI dédié à l’apprentissage d’une langue, le modèle du domaine intégrerait non seulement la grammaire et le vocabulaire, mais aussi des éléments culturels et contextuels essentiels à la maîtrise de la langue. Le modèle pédagogique pourrait inclure des méthodes telles que l’immersion linguistique, les dialogues interactifs, et les jeux de rôle. Le modèle de l’apprenant suivrait les progrès de l’élève en compréhension orale et écrite, en expression, et en grammaire, s’ajustant pour cibler les domaines nécessitant une attention supplémentaire. Enfin, l’interface serait conçue pour encourager l’engagement et la pratique active, avec des fonctionnalités comme la reconnaissance vocale pour la pratique de la prononciation et des simulations de conversation.\nEn intégrant ces éléments, un STI pour l’apprentissage des langues ne se contente pas de transmettre des connaissances ; il crée un environnement riche et interactif où l’apprenant peut s’immerger dans la langue et la culture, favorisant ainsi une expérience d’apprentissage plus naturelle et efficace.\n\n\n\n\n\n\nLes modèles génératifs, tels que les grands modèles de langage basés sur l’intelligence artificielle, offrent une capacité de génération de contenu dynamique et contextuel. Dans un STI pour l’apprentissage des langues, ces modèles peuvent produire des dialogues réalistes, des exercices de compréhension, ou même des scénarios interactifs. Cette capacité de génération de contenu enrichit le modèle du domaine en fournissant une variété de matériel éducatif, allant des phrases simples aux dialogues complexes, adaptés au niveau de compétence de l’élève.\n\n\n\nLes modèles génératifs permettent une personnalisation plus profonde dans le modèle de l’apprenant. En analysant les réponses et les interactions de l’élève, le système peut ajuster dynamiquement le contenu pour cibler les zones de faiblesse, offrir des défis appropriés, et encourager la progression. De plus, ces modèles peuvent simuler des conversations réelles, permettant aux élèves de pratiquer la langue dans un contexte plus naturel et engageant.\n\n\n\nDans le modèle pédagogique, les modèles génératifs contribuent à fournir un retour d’information instantané et contextualisé. Par exemple, après un exercice de dialogue, le système peut offrir des corrections, des suggestions et des explications spécifiques, aidant l’apprenant à comprendre et à corriger ses erreurs en temps réel.\n\n\n\nEnfin, dans le modèle de l’interface, l’intégration de l’IA et des modèles génératifs peut rendre l’interaction avec le système plus intuitive et naturelle. Des fonctionnalités comme la reconnaissance vocale avancée et la génération de réponses en langue naturelle rendent l’apprentissage plus immersif et similaire à une interaction humaine.\nEn somme, l’intégration des modèles génératifs dans les STI pour l’apprentissage des langues transforme non seulement la manière dont le contenu éducatif est présenté, mais aussi la façon dont les élèves interagissent avec ce contenu, rendant l’expérience d’apprentissage plus riche, personnalisée et efficace."
  },
  {
    "objectID": "posts/rl-algorithm-code/index.html",
    "href": "posts/rl-algorithm-code/index.html",
    "title": "Régression linéaire code Python",
    "section": "",
    "text": "Dans ce notebook, nous allons voir comment implémenter une régression linéaire en Python. Nous n’allons pas utiliser de bibliothèques pour ce faire, mais nous allons plutôt implémenter l’algorithme de régression linéaire à partir de zéro. Nous allons également voir comment utiliser notre implémentation pour prédire des valeurs à partir d’un ensemble de données.\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt \nfrom utils import *\n\n/var/folders/yj/l9r_dtt126ncwq1x9jfz7xkw0000gn/T/ipykernel_52250/702382961.py:1: DeprecationWarning: \nPyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\nbut was not found to be installed on your system.\nIf this would cause problems for you,\nplease provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n        \n  import pandas as pd"
  },
  {
    "objectID": "posts/rl-algorithm-code/index.html#implémentation-de-lalgorithme-de-régression-linéaire",
    "href": "posts/rl-algorithm-code/index.html#implémentation-de-lalgorithme-de-régression-linéaire",
    "title": "Régression linéaire code Python",
    "section": "Implémentation de l’algorithme de régression linéaire",
    "text": "Implémentation de l’algorithme de régression linéaire\nLinear regression is a fundamental model in machine learning used for predicting a continuous output variable based on input features. The model function for linear regression is represented as:\n\\[f_{w,b}(x) = wx + b\\]\nIn this equation, \\(f_{w,b}(x)\\) represents the predicted output, \\(w\\) is the weight parameter, \\(b\\) is the bias parameter, and \\(x\\) is the input feature."
  },
  {
    "objectID": "posts/rl-algorithm-code/index.html#model-training",
    "href": "posts/rl-algorithm-code/index.html#model-training",
    "title": "Régression linéaire code Python",
    "section": "Model Training",
    "text": "Model Training\nTo train a linear regression model, we aim to find the best values for the parameters \\((w, b)\\) that best fit our dataset.\n\nForward Pass\nThe forward pass is a step where we compute the linear regression output for the input data \\(X\\) using the current weights and biases. It’s essentially applying our model to the input data.\n\n\nCost Function\nThe cost function is used to measure how well our model is performing. It quantifies the difference between the predicted values and the actual values in our dataset. The cost function is defined as:\n\\[J(w,b) = \\frac{1}{2m} \\sum_{i=1}^{m}(f_{w,b}(x^{(i)}) - y^{(i)})^2\\]\nHere, \\(J(w, b)\\) is the cost, \\(m\\) is the number of training examples, \\(x^{(i)}\\) is the input data for the \\(i\\)-th example, \\(y^{(i)}\\) is the actual output for the \\(i\\)-th example, and \\(w\\) and \\(b\\) are the weight and bias parameters, respectively. **** ### Backward Pass (Gradient Computation)\nThe backward pass computes the gradients of the cost function with respect to the weights and biases. These gradients are crucial for updating the model parameters during training. The gradient formulas are as follows: \\[\n\\frac{\\partial J(w,b)}{\\partial b} = \\frac{1}{m} \\sum_{i=0}^{m-1} (f_{w,b}(X^{(i)}) - y^{(i)})\n\\]\n\\[\n\\frac{\\partial J(w,b)}{\\partial w} = \\frac{1}{m} \\sum_{i=0}^{m-1} (f_{w,b}(X^{(i)}) - y^{(i)})X^{(i)}\n\\]"
  },
  {
    "objectID": "posts/rl-algorithm-code/index.html#training-process",
    "href": "posts/rl-algorithm-code/index.html#training-process",
    "title": "Régression linéaire code Python",
    "section": "Training Process",
    "text": "Training Process\nThe training process involves iteratively updating the weights and biases to minimize the cost function. This is typically done through an optimization algorithm like gradient descent. The update equations for parameters are:\n\\[w \\leftarrow w - \\alpha \\frac{\\partial J}{\\partial w}\\]\n\\[b \\leftarrow b - \\alpha \\frac{\\partial J}{\\partial b}\\]\nHere, \\(\\alpha\\) represents the learning rate, which controls the step size during parameter updates.\nBy iteratively performing the forward pass, computing the cost, performing the backward pass, and updating the parameters, the model learns to make better predictions and fit the data.\n\nrl = LinearRegression(X_train, y_train)\nrl.forward_pass()\n\narray([[1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.]])"
  },
  {
    "objectID": "posts/regression/index.html",
    "href": "posts/regression/index.html",
    "title": "Régression linéaire simple avec Python",
    "section": "",
    "text": "Les données sont disponibles sur Kaggle. Il s’agit d’un ensemble de données de régression linéaire aléatoire avec 2 variables. Bien que très simple, il est idéal pour illustrer le fonctionnement de la régression linéaire.\nLe but de ce notebook est de construire un modèle de régression linéaire en Python et sans aucune librairie pour prédire la variable dépendante y à partir de la variable indépendante x.\n# Importing libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom utils import *"
  },
  {
    "objectID": "posts/regression/index.html#chargement-et-visualisation-des-données",
    "href": "posts/regression/index.html#chargement-et-visualisation-des-données",
    "title": "Régression linéaire simple avec Python",
    "section": "Chargement et visualisation des données",
    "text": "Chargement et visualisation des données\nGrâce à la librairie pandas, nous pouvons charger les données depuis un fichier CSV et les stocker dans un DataFrame. Nous pouvons ensuite visualiser les données avec la librairie matplotlib.\n\n\ndataset = pd.read_csv('data/train.csv')\ndataset_test = pd.read_csv('data/test.csv')\ndataset.head()\n\n\n\n\n\n\n\n\nx\ny\n\n\n\n\n0\n24.0\n21.549452\n\n\n1\n50.0\n47.464463\n\n\n2\n15.0\n17.218656\n\n\n3\n38.0\n36.586398\n\n\n4\n87.0\n87.288984\n\n\n\n\n\n\n\nLa méthode head() permet d’afficher les 5 premières lignes du DataFrame. Et la méthode describe() permet d’afficher des statistiques descriptives sur les données.\nCes deux méthodes sont très utiles pour avoir un aperçu des données.\n\ndataset.describe()\n\n\n\n\n\n\n\n\nx\ny\n\n\n\n\ncount\n700.000000\n699.000000\n\n\nmean\n54.985939\n49.939869\n\n\nstd\n134.681703\n29.109217\n\n\nmin\n0.000000\n-3.839981\n\n\n25%\n25.000000\n24.929968\n\n\n50%\n49.000000\n48.973020\n\n\n75%\n75.000000\n74.929911\n\n\nmax\n3530.157369\n108.871618\n\n\n\n\n\n\n\nIl est primordial de comprendre les données avant de commencer à les analyser. Il faut donc visualiser les données pour voir s’il y a des relations entre les variables et/ou des valeurs aberrantes ou manquantes.\n\ndataset.isna().values.any()\n\nTrue\n\n\nComme nous sommes en présence de données manquantes, nous devons les gérer avant de commencer à construire notre modèle. Il existe plusieurs méthodes pour gérer les données manquantes. Dans un prochain notebook nous verrons les différentes méthodes pour gérer les données manquantes. Pour l’heure nous allons simplement supprimer les lignes qui contiennent des données manquantes.\n\ndataset = dataset.dropna()\n\n\ndataset.isna().values.any()\n\nFalse\n\n\nIci, nous avons deux variables : la variable indépendante X et la variable dépendante y. Nous pouvons visualiser les données avec un nuage de points.\n\nDistribution des données\nL’analyse de la distribution des données est importante pour comprendre les données. Nous pouvons visualiser la distribution des données avec un histogramme.\nNous pouvons voir que les données sont distribuées uniformement, ce qui est une bonne chose pour la régression linéaire.\n\n# Plotting the distribution of the data\ndataset.hist(bins=30, figsize=(20,15))\nplt.show()\n\n\n\n\n\n\n\n\n\n# Plotting the correlation matrix\ncorr_matrix = dataset.corr()\ncorr_matrix['y'].sort_values(ascending=False)\n\ny    1.00000\nx    0.99534\nName: y, dtype: float64\n\n\n\n\nLa corrélation entre les variables\nLa corrélation entre X et y est très importante pour la régression linéaire. Plus la corrélation est forte, plus la régression linéaire sera efficace.\nIci, sans surprise puisque le dataset a été créé à cet effet, nous avons une corrélation très forte entre X et y.\n\nimport seaborn as sns\n\n# Calculer le coefficient de corrélation de Pearson\ncorrelation_matrix = dataset.corr()\n\n# Afficher le coefficient de corrélation\nprint(\"Coefficient de corrélation de Pearson entre x et y :\")\nprint(correlation_matrix.loc['x', 'y'])\n\n# Visualiser la corrélation avec un nuage de points\nplt.figure(figsize=(6, 4))\nsns.scatterplot(x='x', y='y', data=dataset)\nplt.title('Nuage de points de x contre y')\nplt.show()\n\n# Visualiser la matrice de corrélation avec une heatmap\nplt.figure(figsize=(5, 4))\nsns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\nplt.title('Matrice de corrélation')\nplt.show()\n\nCoefficient de corrélation de Pearson entre x et y :\n0.9953399077212526"
  },
  {
    "objectID": "posts/regression/index.html#préparation-des-données",
    "href": "posts/regression/index.html#préparation-des-données",
    "title": "Régression linéaire simple avec Python",
    "section": "Préparation des données",
    "text": "Préparation des données\n\nSéparation des données en deux variables : variable indépendante X et variable dépendante y\nConversion des données en tableaux Numpy\n\n\ncolumns = dataset.columns\ncolumns\n\nIndex(['x', 'y'], dtype='object')\n\n\n\nX_full = dataset.x.to_numpy()\ny_full = dataset.y.to_numpy()\n\n\nDivision des données\nNous passons ensuite à diviser notre dataset en données d’entraînement et données de test puis en données d’entraînement et données de validation.al\nLe dataset dispose d’un second ficher test.csv qui contient des données de test. Mais nous allons, à des fins d’entraînement, ne pas en tenir compte jusqu’à la fin. Une foid le modèle construit, nous pourrons entraîner avec l’entièreté des données d’entraînement puis l’évaluer avec ces données de test.\n\nX_train, X_val, y_train, y_val = dataset_splitter(X_full, y_full, 0.4)\nX_val, y_val, X_test, y_test = dataset_splitter(X_val, y_val, 0.5)\n\nX type: &lt;class 'numpy.ndarray'&gt;\ny type: &lt;class 'numpy.ndarray'&gt;\nX type: &lt;class 'numpy.ndarray'&gt;\ny type: &lt;class 'numpy.ndarray'&gt;\ntrain_size: 60.0% - test_size: 40.0%\nX_train: 60%\nX_val: 40%\nX type: &lt;class 'numpy.ndarray'&gt;\ny type: &lt;class 'numpy.ndarray'&gt;\nX type: &lt;class 'numpy.ndarray'&gt;\ny type: &lt;class 'numpy.ndarray'&gt;\ntrain_size: 50.0% - test_size: 50.0%\nX_train: 50%\nX_val: 50%\n\n\n\n\nStandardisation des données\nCette étape est importante car elle permet d’éviter que certaines variables aient plus d’importance que d’autres dans le modèle. En effet, si une variable est exprimée en milliers et une autre en unités, la variable exprimée en milliers aura plus d’importance dans le modèle. Il faut donc standardiser les données pour que toutes les variables aient la même importance.\nDeplus, cela permet d’accélérer la convergence de l’algorithme d’optimisation et éviter les problèmes de précision ou d’overflow.\n\n# Normalizing the data\nX_train = normalize(X_train)\nprint(X_train[:4])\nprint(y_train[:4])\n\n[0.29 0.58 0.84 0.76]\n[29.6673599  56.68718792 85.02778957 73.13850045]"
  },
  {
    "objectID": "posts/regression/index.html#entraînement-du-modèle",
    "href": "posts/regression/index.html#entraînement-du-modèle",
    "title": "Régression linéaire simple avec Python",
    "section": "Entraînement du modèle",
    "text": "Entraînement du modèle\nNous allons maintenant entraîner notre modèle. Pour cela, nous allons utiliser le gradient descent. Il s’agit d’un algorithme d’optimisation qui permet de trouver le minimum d’une fonction. Dans notre cas, il s’agit de trouver les paramètres de notre modèle qui minimisent la fonction de coût.\nLa fonction de coût est une fonction qui permet de mesurer l’erreur de notre modèle. Plus l’erreur est grande, plus la fonction de coût est grande. L’objectif est donc de trouver les paramètres de notre modèle qui minimisent la fonction de coût.\nNous utilisons la fonction de coût MSE (Mean Squared Error) qui est la moyenne des erreurs au carré. Il s’agit de la fonction de coût la plus utilisée pour la régression linéaire.\n\n# Initialisation des paramètres\nw_init = 1\nb_init = 1\n# hyperparameters\niterations = 20000\ntmp_alpha = 1.5e-2\n# On effectue la descente de gradient pour trouver les paramètres w et b\nw_final, b_final, J_history, p_history = gradient_descent(\n    X_train,\n    y_train,\n    w_init,\n    b_init,\n    tmp_alpha,\n    iterations,\n    compute_cost,\n    compute_gradient)\nprint(f\"(w,b) found by gradient descent: ({w_final},{b_final})\")\n\nIteration 0: Cost 1551.859965285387  dj_dw: -32.873739546586314, dj_db: -48.578447077520295   w: 1.4931060931987947, b:1.7286767061628043\nIteration 2000: Cost 8.423656158596158  dj_dw: -0.6831496603139884, dj_db: 0.3678205742662411   w: 89.65499284685094, b:5.442780552104867\nIteration 4000: Cost 4.0614640156356385  dj_dw: -0.08960525186481552, dj_db: 0.04824514614125734   w: 98.41652047287423, b:0.7254099522683186\nIteration 6000: Cost 3.9864158627776507  dj_dw: -0.011753063242489757, dj_db: 0.006328069414907828   w: 99.56572530346672, b:0.10665654391001181\nIteration 8000: Cost 3.985124717164894  dj_dw: -0.0015415892786128443, dj_db: 0.0008300205455334563   w: 99.71646063171404, b:0.025497819520598132\nIteration 10000: Cost 3.9851025040000105  dj_dw: -0.00020220239226366815, dj_db: 0.00010886955575859842   w: 99.73623181486332, b:0.01485264414783104\nIteration 12000: Cost 3.9851021218396427  dj_dw: -2.6521855068231795e-05, dj_db: 1.4279863596465318e-05   w: 99.73882509997904, b:0.013456370862629252\nIteration 14000: Cost 3.985102115264865  dj_dw: -3.478736276372286e-06, dj_db: 1.8730167755593508e-06   w: 99.73916524794275, b:0.013273228827112946\nIteration 16000: Cost 3.9851021151517485  dj_dw: -4.5628806805420693e-07, dj_db: 2.456740467172917e-07   w: 99.73920986341393, b:0.013249207021663368\nIteration 18000: Cost 3.9851021151498016  dj_dw: -5.984895811768687e-08, dj_db: 3.222382454426939e-08   w: 99.73921571539752, b:0.013246056204090619\n(w,b) found by gradient descent: (99.73921648285449,0.013245642990875566)\n\n\nUne fois le modèle entraîné, nous pouvons visualiser la fonction de coût en fonction des itérations. Nous pouvons voir que la fonction de coût diminue au fur et à mesure des itérations. Cela signifie que notre modèle s’améliore au fur et à mesure des itérations.\nIl nous reste à effectuer les prédictions sur les données de test et à évaluer notre modèle.\n\n# Making predictions on the training set\nX_train = normalize(X_train)\ny_train_pred = compute_model_output(X_train, w_final, b_final)\n# Computing the RMSE on the training set\nmse_train = compute_mse(y_train, y_train_pred)\nprint(f\"MSE on the training set: {mse_train}\")\n\n# Making predictions on the validation set\nX_val = normalize(X_val)\ny_val_pred = compute_model_output(X_val, w_final, b_final)\n# Computing the MSE on the validation set\nmse_val = compute_mse(y_val, y_val_pred)\nprint(f\"MSE on the validation set: {mse_val}\")\n\nprint(y_val[:4])\nprint(y_val_pred[:4])\n\nMSE on the training set: 3339.515572495507\nMSE on the validation set: 231487.7780914846\n[94. 75. 65. 84.]\n[14.97412812 70.82808935 48.88546172  5.99759863]\n\n\n\n# Comparaison avec la regression linéaire de scikit-learn\nfrom sklearn.linear_model import LinearRegression\n\n# reshape X_train and y_train to be 2D\nX_train_sk = X_train.reshape(-1, 1)\ny_train_sk = y_train.reshape(-1, 1)\n\n# create linear regression object\nregr = LinearRegression()\n\n# train the model using the training sets\nregr.fit(X_train_sk, y_train_sk)\nprint(f\"(w,b) found by sklearn: ({regr.coef_},{regr.intercept_})\")\n\n# make predictions using the testing set\ny_train_pred_sk = regr.predict(X_train_sk)\n# compute MSE for the training set\nmse_train_sk = compute_mse(y_train.reshape(-1, 1), y_train_pred_sk)\nprint(f\"MSE sklearn training set = {mse_train_sk}\")\n\n# Train sklearn model on the validation set\nX_val_sk = X_val.reshape(-1, 1)\ny_val_pred_sk = regr.predict(X_val_sk)\n# compute MSE for the validation set\nmse_val_sk = compute_mse(y_val.reshape(-1, 1), y_val_pred_sk)\nprint(f\"MSE sklearn validation set = {mse_val_sk}\")\n\n(w,b) found by sklearn: ([[99.7392166]],[0.01324558])\nMSE sklearn training set = [3339.5155725]\nMSE sklearn validation set = [231487.77835407]\n\n\n\n# plot cost versus iteration\nfig, (ax1, ax2) = plt.subplots(1, 2, constrained_layout=True, figsize=(12, 4))\nax1.plot(J_history[:1000])\nax2.plot(10 + np.arange(len(J_history[1000:])), J_history[1000:])\nax1.set_title(\"Cost vs. iteration(start)\")\nax2.set_title(\"Cost vs. iteration (end)\")\nax1.set_ylabel('Cost')\nax2.set_ylabel('Cost')\nax1.set_xlabel('iteration step')\nax2.set_xlabel('iteration step')\nplt.show()\n\n\n\n\n\n\n\n\n\n# Entraînement du modèle sur le jeu de données complet\n# Normalizing the data  \nX_full = normalize(X_full)\nw_init = 1\nb_init = 1\n# some gradient descent settings\niterations = 10000\ntmp_alpha = 1.5e-2\n# run gradient descent\nw_final, b_final, J_history, p_history = gradient_descent(\n    X_full,\n    y_full,\n    w_init,\n    b_init,\n    tmp_alpha,\n    iterations,\n    compute_cost,\n    compute_gradient)\nprint(f\"(w,b) found by gradient descent: ({w_final},{b_final})\")\n\nIteration 0: Cost 1537.3567329291454  dj_dw: -32.52024298395501, dj_db: -48.43972610894132   w: 1.487803644759325, b:1.7265958916341198\nIteration 1000: Cost 38.98085747456498  dj_dw: -1.8984414216810792, dj_db: 1.016621137292813   w: 71.34361556464307, b:15.273469067109064\nIteration 2000: Cost 8.763458563326123  dj_dw: -0.7047363066142613, dj_db: 0.37738854099322106   w: 89.40349545087861, b:5.6023459928707755\nIteration 3000: Cost 4.599407703716551  dj_dw: -0.26161107161811215, dj_db: 0.14009356364788061   w: 96.10765480886297, b:2.012247263814149\nIteration 4000: Cost 4.025588639661802  dj_dw: -0.09711483877137726, dj_db: 0.05200530605382486   w: 98.59636199973698, b:0.6795366216797071\nIteration 5000: Cost 3.9465146010936167  dj_dw: -0.036050813336207035, dj_db: 0.019305325579060225   w: 99.52021585689978, b:0.18480993316743607\nIteration 6000: Cost 3.9356179544550427  dj_dw: -0.013382724603611356, dj_db: 0.007166491729286533   w: 99.86316739114395, b:0.0011582922273052087\nIteration 7000: Cost 3.9341163629072184  dj_dw: -0.0049679133767509, dj_db: 0.0026603334657992147   w: 99.99047730485871, b:-0.06701657281066145\nIteration 8000: Cost 3.933909438956092  dj_dw: -0.0018441807666289998, dj_db: 0.0009875646852625613   w: 100.03773708506571, b:-0.09232433591668049\nIteration 9000: Cost 3.933880924196801  dj_dw: -0.0006845938006577501, dj_db: 0.00036660216479203765   w: 100.05528078421726, b:-0.10171904279395448\n(w,b) found by gradient descent: (100.061789515827,-0.10520448934023051)\n\n\n\n# Preparation du jeu de test\nX_test = dataset_test.x.to_numpy().reshape(-1, 1)   \ny_test_final = dataset_test.y.to_numpy().reshape(-1, 1)\n\n\n# Evaluation du modèle sur le jeu de test\n# Normalizing the data\nX_test_norm = normalize(X_test)\ny_test_pred = compute_model_output(X_test_norm, w_final, b_final)\n\nmse_test = compute_mse(y_test_final, y_test_pred.reshape(-1, 1))\nprint(f\"MSE on the test set: {mse_test}\")\n\nMSE on the test set: [2830.11215745]\n\n\n\n\n# reshape X_train and y_train to be 2D\nX_full_sk = X_full.reshape(-1, 1)\ny_full_sk = y_full.reshape(-1, 1)\nX_test_sk = normalize(X_test).reshape(-1, 1)\n\n# create linear regression object\nregr = LinearRegression()\n# train the model using the training sets\nregr.fit(X_full_sk, y_full_sk)\n\n# make predictions using the testing set\ny_test_pred_sk = regr.predict(X_test_sk)\n# compute MSE for the training set\nmse_test_sk = compute_mse(y_test_final, y_test_pred_sk)\nprint(f\"MSE = {mse_test_sk}\")\n\nMSE = [2829.87665761]"
  },
  {
    "objectID": "posts/virtual-environnements/js_env.html",
    "href": "posts/virtual-environnements/js_env.html",
    "title": "Environnements virtuels avec Javascript",
    "section": "",
    "text": "Dans le monde du développement logiciel, l’utilisation d’environnements virtuels est devenue une pratique essentielle, surtout lorsqu’il s’agit de gérer des projets complexes avec de nombreuses dépendances. Cet article se concentre sur l’écosystème JavaScript et explore l’utilisation d’outils tels que Git, npm et yarn dans le cadre de ces environnements."
  },
  {
    "objectID": "posts/virtual-environnements/js_env.html#pourquoi-utiliser-des-environnements-virtuels",
    "href": "posts/virtual-environnements/js_env.html#pourquoi-utiliser-des-environnements-virtuels",
    "title": "Environnements virtuels avec Javascript",
    "section": "Pourquoi Utiliser des Environnements Virtuels ?",
    "text": "Pourquoi Utiliser des Environnements Virtuels ?\nLes environnements virtuels sont des espaces isolés où les développeurs peuvent gérer les dépendances de leurs projets de manière indépendante et sécurisée. Voici pourquoi ils sont si cruciaux :\n\nIsolation : Dans un environnement virtuel, chaque projet possède son propre ensemble de dépendances, isolé des autres projets. Cela signifie que vous pouvez travailler sur plusieurs projets ayant des besoins différents en termes de versions de bibliothèques sans que l’un interfère avec l’autre.\nReproductibilité : Les environnements virtuels assurent que votre projet fonctionnera de la même manière sur tous les systèmes où il est déployé. En définissant clairement les dépendances, vous évitez les problèmes liés aux différences de configurations entre les environnements de développement et de production.\nÉviter les Conflits : L’utilisation d’environnements virtuels aide à prévenir les conflits entre les différentes versions des paquets nécessaires pour différents projets. Cela évite les situations où la mise à jour d’une bibliothèque pour un projet casse un autre projet dépendant d’une version antérieure."
  },
  {
    "objectID": "posts/virtual-environnements/js_env.html#environnements-virtuels-dans-javascript",
    "href": "posts/virtual-environnements/js_env.html#environnements-virtuels-dans-javascript",
    "title": "Environnements virtuels avec Javascript",
    "section": "Environnements Virtuels dans JavaScript",
    "text": "Environnements Virtuels dans JavaScript\n\nLe monde de JavaScript est vaste et en constante évolution, avec un écosystème riche en bibliothèques et outils. L’utilisation d’environnements virtuels dans ce contexte prend une importance particulière pour plusieurs raisons :\nGestion des Dépendances Complexes : JavaScript, en particulier avec Node.js, implique souvent de gérer de nombreuses dépendances, ce qui peut rapidement devenir complexe. Les environnements virtuels permettent de gérer ces dépendances de manière ordonnée, en s’assurant que chaque projet dispose de la version correcte de chaque paquet.\nDéveloppement Modulaire : JavaScript est célèbre pour son approche modulaire. Dans un environnement virtuel, il est plus facile de tester différents modules et de s’assurer qu’ils fonctionnent bien ensemble, sans affecter d’autres projets.\nCollaboration et Consistance : En partageant un environnement virtuel bien défini entre les membres d’une équipe, on assure une uniformité dans le processus de développement, réduisant ainsi les problèmes liés aux différences d’environnements de travail."
  },
  {
    "objectID": "posts/virtual-environnements/js_env.html#gestion-des-dépendances-avec-git",
    "href": "posts/virtual-environnements/js_env.html#gestion-des-dépendances-avec-git",
    "title": "Environnements virtuels avec Javascript",
    "section": "Gestion des Dépendances avec Git",
    "text": "Gestion des Dépendances avec Git\nBien que Git soit principalement connu comme un outil de contrôle de version, il joue également un rôle crucial dans la gestion des dépendances dans les projets JavaScript :\n\nContrôle de Version et Dépendances : Git permet de suivre les modifications apportées aux fichiers de dépendances, comme le package.json dans les projets Node.js. Cela aide à maintenir une historique claire des changements apportés aux dépendances et facilite la gestion des mises à jour ou des régressions.\nBranches pour Gérer les Dépendances : L’utilisation des branches Git permet de tester de nouvelles versions de dépendances sans affecter la branche principale. Cela rend les expérimentations plus sûres et réduit les risques de perturbations dans le projet principal.\nIntégration avec les Outils de CI/CD : En utilisant Git, les développeurs peuvent intégrer facilement leur gestion de dépendances avec des systèmes d’intégration continue et de déploiement continu (CI/CD), garantissant que les modifications de dépendances sont correctement testées avant d’être déployées."
  },
  {
    "objectID": "posts/virtual-environnements/js_env.html#npm-et-yarn-dans-les-environnements-virtuels-comparaison-et-pratiques",
    "href": "posts/virtual-environnements/js_env.html#npm-et-yarn-dans-les-environnements-virtuels-comparaison-et-pratiques",
    "title": "Environnements virtuels avec Javascript",
    "section": "NPM et Yarn dans les Environnements Virtuels : Comparaison et Pratiques",
    "text": "NPM et Yarn dans les Environnements Virtuels : Comparaison et Pratiques\nBien que npm et Yarn soient tous deux utilisés pour la gestion des dépendances dans les projets JavaScript, ils présentent des différences et des similarités notables :\n\nFonctionnalités Communes : npm et Yarn servent tous deux à gérer les dépendances des projets Node.js, utilisant un dossier node_modules pour les installations locales. Chacun commence par initialiser un projet (npm avec npm init et Yarn avec yarn init) et gère les dépendances avec un fichier de verrouillage (package-lock.json pour npm et yarn.lock pour Yarn).\nAvantages de Yarn sur npm : Yarn est reconnu pour sa vitesse supérieure, sa gestion efficace du cache et ses fonctionnalités avancées comme les Workspaces. Yarn offre également une meilleure fiabilité avec son fichier yarn.lock, qui enregistre des informations plus détaillées sur les versions exactes des paquets installés.\nGestion des Dépendances : Les deux outils permettent d’ajouter, de mettre à jour et de supprimer des paquets facilement (npm avec npm install/add, npm update et npm remove; Yarn avec yarn add, yarn upgrade, et yarn remove).\nMeilleures Pratiques : Il est crucial de maintenir les dépendances à jour et de comprendre l’impact des mises à jour sur votre projet. Que vous utilisiez npm ou Yarn, une gestion attentive des dépendances directes et indirectes est essentielle pour la santé et la sécurité du projet."
  },
  {
    "objectID": "posts/virtual-environnements/js_env.html#conclusion",
    "href": "posts/virtual-environnements/js_env.html#conclusion",
    "title": "Environnements virtuels avec Javascript",
    "section": "Conclusion",
    "text": "Conclusion\nL’utilisation d’environnements virtuels et la gestion efficace des dépendances sont des piliers essentiels dans le développement moderne de logiciels, en particulier dans l’écosystème JavaScript. Que ce soit à travers npm ou Yarn, la capacité de gérer les dépendances de manière isolée et reproductible est cruciale pour la réussite et la stabilité des projets.\nEn embrassant ces outils et pratiques, les développeurs peuvent non seulement améliorer la qualité et la fiabilité de leurs applications, mais aussi faciliter la collaboration au sein des équipes et entre les projets. Il est important de rester à jour avec les meilleures pratiques et les nouvelles fonctionnalités offertes par ces outils, afin de tirer le meilleur parti des technologies disponibles.\nEn conclusion, les environnements virtuels et la gestion adéquate des dépendances ne sont pas seulement des facilitateurs techniques ; ils représentent une approche stratégique vers un développement plus ordonné, sécurisé et collaboratif."
  },
  {
    "objectID": "archive.html",
    "href": "archive.html",
    "title": "Archive",
    "section": "",
    "text": "Dico, première version\n\n\n\n\n\n\n\n\nJan 21, 2024\n\n\n\n\n\n\n\nEnvironnements virtuels avec Javascript\n\n\n\n\n\n\n\n\nJan 21, 2024\n\n\n\n\n\n\n\nEnvironnements virtuels avec Python\n\n\n\n\n\n\n\n\nJan 21, 2024\n\n\n\n\n\n\n\nL’Education 2.0\n\n\n\n\n\n\n\n\nJan 19, 2024\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Series",
    "section": "",
    "text": "Series\n\nenvironnements virtuels\nCeci est une série d’articles sur les environnements virtuels.\n\n\nDico\nDico, le dictionnaire qui éduque les élèves à l’utiliser judicieusement, les guidant vers une autonomie linguistique et numérique.\n \n\n\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRégression linéaire code Python\n\n\n\n\n\n\nData Science\n\n\nPython\n\n\n\n\n\n\n\n\n\nFeb 2, 2024\n\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\n\nRégression linéaire simple avec Python\n\n\n\n\n\n\nData Science\n\n\nPython\n\n\n\n\n\n\n\n\n\nJan 30, 2024\n\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\n\nDico, première version\n\n\n\n\n\n\nAPI\n\n\ndictionnaire\n\n\néducation\n\n\nnumérique\n\n\nautonomie\n\n\nlinguistique\n\n\n\n\n\n\n\n\n\nJan 21, 2024\n\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\n\nEnvironnements virtuels avec Javascript\n\n\n\n\n\n\nGit\n\n\nJavascript\n\n\nNodeJS\n\n\nNPM\n\n\nYarn\n\n\n\n\n\n\n\n\n\nJan 21, 2024\n\n\n5 min\n\n\n\n\n\n\n\n\n\n\n\n\nEnvironnements virtuels avec Python\n\n\n\n\n\n\nVenv\n\n\nPython\n\n\nAnaconda\n\n\n\n\n\n\n\n\n\nJan 21, 2024\n\n\n6 min\n\n\n\n\n\n\n\n\n\n\n\n\nL’Education 2.0\n\n\n\n\n\n\neducation\n\n\nSTI\n\n\nLLM\n\n\n\n\n\n\n\n\n\nJan 19, 2024\n\n\n6 min\n\n\n\n\n\n\n\n\n\n\n\n\nMon premier modèle d’apprentissage automatique\n\n\n\n\n\n\nAI\n\n\nMachine Learning\n\n\nPython\n\n\nFastai\n\n\n\n\n\n\n\n\n\nJan 12, 2024\n\n\n1 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "env-series.html",
    "href": "env-series.html",
    "title": "Series: environments virtuels",
    "section": "",
    "text": "Environnements virtuels avec Javascript\n\n\n\n\n\n\n\n\n\n\n\nJan 21, 2024\n\n\n5 min\n\n\n\n\n\n\n\nEnvironnements virtuels avec Python\n\n\n\n\n\n\n\n\n\n\n\nJan 21, 2024\n\n\n6 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/virtual-environnements/python_env.html#introduction-à-python-et-aux-environnements-virtuels",
    "href": "posts/virtual-environnements/python_env.html#introduction-à-python-et-aux-environnements-virtuels",
    "title": "Environnements virtuels avec Python",
    "section": "Introduction à Python et aux Environnements Virtuels",
    "text": "Introduction à Python et aux Environnements Virtuels\nPython, l’un des langages de programmation les plus populaires et polyvalents, est largement utilisé dans divers domaines, allant du développement web à la science des données. Une caractéristique clé de Python est sa capacité à créer et à gérer des environnements virtuels. Ces environnements sont des espaces isolés qui permettent aux développeurs d’installer et de gérer des paquets spécifiques à chaque projet sans affecter les autres projets ou le système global. Cette isolation évite les conflits de dépendances et assure une plus grande reproductibilité des projets."
  },
  {
    "objectID": "posts/virtual-environnements/python_env.html#création-dun-environnement-virtuel-avec-python",
    "href": "posts/virtual-environnements/python_env.html#création-dun-environnement-virtuel-avec-python",
    "title": "Environnements virtuels avec Python",
    "section": "Création d’un Environnement Virtuel avec Python",
    "text": "Création d’un Environnement Virtuel avec Python\nPython offre un outil intégré, venv, pour créer des environnements virtuels. Voici comment vous pouvez créer et activer un environnement virtuel :\nCréation de l’Environnement :\npython -m venv mon_env\nCette commande crée un nouvel environnement virtuel nommé mon_env.\nActivation de l’Environnement :\nSur Windows :\nmon_env\\Scripts\\activate\nSur Unix ou MacOS :\nsource mon_env/bin/activate\nCette étape active l’environnement virtuel, isolant ainsi vos installations de paquets.\nTrès bien, abordons maintenant la section sur Conda :\nIntroduction à Conda pour les Environnements Virtuels\nConda est un puissant gestionnaire de paquets et d’environnements virtuels qui se distingue dans la gestion des dépendances en Python. Contrairement à venv, qui est spécifique à Python, Conda est langage agnostique, ce qui lui permet de gérer des paquets dans plusieurs langages. Cela est particulièrement utile dans les projets interdisciplinaires qui impliquent différentes technologies."
  },
  {
    "objectID": "posts/virtual-environnements/python_env.html#création-dun-environnement-avec-conda",
    "href": "posts/virtual-environnements/python_env.html#création-dun-environnement-avec-conda",
    "title": "Environnements virtuels avec Python",
    "section": "Création d’un Environnement avec Conda :",
    "text": "Création d’un Environnement avec Conda :\n\nInstallation de Conda :\nPour installer Conda, vous pouvez télécharger et exécuter le script d’installation Anaconda ou Miniconda . Vous pouvez également installer Conda à l’aide de pip, le gestionnaire de paquets Python. Pour ce faire, exécutez la commande suivante :\npip install conda\n\n\nCréation de l’Environnement Conda :\nconda create --name mon_env_python python=3.8\nCette commande crée un environnement Conda nommé mon_env_python avec une version spécifique de Python.\nActivation de l’Environnement Conda :\nconda activate mon_env_python\nEn activant l’environnement, vous isolez vos travaux et dépendances dans cet environnement.\n\n\nAvantages de Conda :\n\nGestion Multilingue : Conda peut gérer des paquets de différents langages, ce qui le rend idéal pour les projets complexes.\nEnvironnements Plus Robustes : Conda facilite la création et la gestion d’environnements avec des dépendances complexes et interdépendantes.\nIntégration avec des Outils Scientifiques : Conda est très populaire dans les communautés scientifiques et de data science pour sa capacité à gérer efficacement des bibliothèques scientifiques et des outils d’analyse de données."
  },
  {
    "objectID": "posts/virtual-environnements/python_env.html#gestion-des-dépendances-avec-conda",
    "href": "posts/virtual-environnements/python_env.html#gestion-des-dépendances-avec-conda",
    "title": "Environnements virtuels avec Python",
    "section": "Gestion des Dépendances avec Conda",
    "text": "Gestion des Dépendances avec Conda\nConda simplifie non seulement la création d’environnements virtuels mais aussi la gestion des dépendances au sein de ces environnements :\n\nInstallation des Paquets avec Conda : Pour installer un paquet dans l’environnement actif, utilisez :\n\nconda install nom_du_paquet\nContrairement à pip, Conda cherche les paquets dans ses propres dépôts, ce qui peut inclure des optimisations spécifiques et des versions pré-compilées.\n\nListe des Paquets Installés : Pour voir les paquets installés dans l’environnement actif :\n\nconda list\n\nMise à jour des Paquets : Pour mettre à jour un paquet spécifique :\n\nbash Copy code conda update nom_du_paquet Ou pour mettre à jour tous les paquets de l’environnement :\nconda update --all\nAvantages de Conda pour la Gestion des Dépendances :\n\nRésolution de Dépendances Complexe :\n\n\nConda gère efficacement les dépendances complexes et leurs interdépendances.\nEnvironnements Consistants : Conda assure une cohérence accrue entre les environnements de développement et de production.\nLarge Éventail de Paquets : Avec Anaconda, Conda offre un accès à une vaste bibliothèque de paquets scientifiques et de data science."
  },
  {
    "objectID": "posts/virtual-environnements/python_env.html#utilisation-de-pip-dans-les-environnements-virtuels",
    "href": "posts/virtual-environnements/python_env.html#utilisation-de-pip-dans-les-environnements-virtuels",
    "title": "Environnements virtuels avec Python",
    "section": "Utilisation de pip dans les Environnements Virtuels",
    "text": "Utilisation de pip dans les Environnements Virtuels\npip est le gestionnaire de paquets par défaut pour Python et est largement utilisé pour installer et gérer les paquets Python. Dans un environnement virtuel, pip est isolé et gère les installations de paquets spécifiques à cet environnement.\n\nInstallation des Paquets avec pip : Dans un environnement virtuel activé, vous pouvez installer des paquets en utilisant :\n\npip install nom_du_paquet\nCela garantit que le paquet est installé uniquement dans l’environnement virtuel, sans affecter d’autres projets ou le système global.\n\nGeler les Dépendances : Pour créer une liste de toutes les dépendances installées dans l’environnement :\n\npip freeze  &gt; requirements.txt\nCe fichier requirements.txt peut être utilisé pour recréer l’environnement ailleurs.\n\nInstaller des Dépendances à partir d’un Fichier requirements.txt :\n\npip install -r requirements.txt\nCette commande installe toutes les dépendances listées dans le fichier requirements.txt.\n\nComparaison entre pip et Conda :\n\n\nCiblage : pip est spécifiquement conçu pour Python, tandis que Conda est polyvalent et peut gérer des paquets dans plusieurs langages.\nSources de Paquets : pip installe des paquets à partir du Python Package Index (PyPI), tandis que Conda utilise ses propres dépôts, souvent optimisés pour des paquets scientifiques et de data science.\nGestion des Dépendances : Conda est généralement plus efficace dans la gestion des dépendances complexes et interdépendantes."
  },
  {
    "objectID": "posts/virtual-environnements/python_env.html#bonnes-pratiques-pour-la-gestion-des-environnements-virtuels",
    "href": "posts/virtual-environnements/python_env.html#bonnes-pratiques-pour-la-gestion-des-environnements-virtuels",
    "title": "Environnements virtuels avec Python",
    "section": "Bonnes Pratiques pour la Gestion des Environnements Virtuels",
    "text": "Bonnes Pratiques pour la Gestion des Environnements Virtuels\nGérer efficacement les environnements virtuels est crucial pour le développement logiciel. Voici quelques bonnes pratiques :\n\nIsolation des Projets : Utilisez des environnements virtuels distincts pour chaque projet afin d’éviter les conflits de dépendances et de garantir que les besoins spécifiques de chaque projet sont satisfaits.\nDocumentation des Dépendances :\n\n\nAvec pip : Utilisez pip freeze pour créer un fichier requirements.txt, qui sert de documentation pour les dépendances du projet.\nAvec Conda : Utilisez conda list –export &gt; environment.yml pour créer un fichier similaire.\n\n\nReproductibilité des Environnements :\n\n\nPartagez les fichiers requirements.txt ou environment.yml au sein de votre équipe pour assurer que tous travaillent avec les mêmes versions de dépendances. 4.Mise à Jour Régulière :\nVérifiez régulièrement les mises à jour des paquets pour bénéficier des dernières fonctionnalités et corrections de sécurité.\n\n\nNettoyage des Environnements :\n\n\nSupprimez les environnements virtuels qui ne sont plus utilisés pour libérer de l’espace et maintenir un système organisé."
  },
  {
    "objectID": "posts/virtual-environnements/python_env.html#conclusion",
    "href": "posts/virtual-environnements/python_env.html#conclusion",
    "title": "Environnements virtuels avec Python",
    "section": "Conclusion",
    "text": "Conclusion\nLes environnements virtuels, que ce soit avec venv, Conda, ou pip, sont des outils essentiels dans le développement en Python. Ils offrent une isolation cruciale, garantissent la reproductibilité des projets et facilitent la gestion des dépendances. Conda, en particulier, se distingue par sa capacité à gérer des dépendances complexes et multi-langages, ce qui en fait un choix privilégié pour des projets scientifiques et de data science.\nLa clé d’un développement efficace et sans heurts réside dans l’utilisation judicieuse de ces outils. En suivant les bonnes pratiques telles que l’isolation des projets, la documentation des dépendances, et la mise à jour régulière, les développeurs peuvent assurer la stabilité et la sécurité de leurs applications.\nEn fin de compte, une bonne maîtrise des environnements virtuels et des outils de gestion de dépendances est un atout indéniable pour tout développeur Python, ouvrant la voie à des projets plus organisés, reproductibles et réussis."
  },
  {
    "objectID": "posts/dico/dico-old.html",
    "href": "posts/dico/dico-old.html",
    "title": "Dico, première version",
    "section": "",
    "text": "Ceci est une traduction de l’article Dico de Jason Suárez, 19 février 2023."
  },
  {
    "objectID": "posts/dico/dico-old.html#quest-ce-que-dico",
    "href": "posts/dico/dico-old.html#quest-ce-que-dico",
    "title": "Dico, première version",
    "section": "Qu’est-ce que Dico ?",
    "text": "Qu’est-ce que Dico ?\nTout d’abord, voici le dépôt Github et le site..\nEnsuite, comme vous l’avez peut-être deviné, Dico est un simple dictionnaire français-espagnol.\nDico vous permet de chercher un mot à la fois dans les deux langues grâce à l’API du Dictionnaire en ligne PONS, pour laquelle vous aurez besoin d’une clé API, mais leur offre gratuite est largement suffisante pour commencer.\nPour ce projet, j’ai utilisé :\n\nTypescript pour des raisons de sécurité\nNext.js pour le front-end et le back-end une base de données PostgreSQL hébergée sur Railway.app\nPrisma comme ORM\nTailwindcss pour le style"
  },
  {
    "objectID": "posts/dico/dico-old.html#lobjectif-de-dico",
    "href": "posts/dico/dico-old.html#lobjectif-de-dico",
    "title": "Dico, première version",
    "section": "L’objectif de Dico",
    "text": "L’objectif de Dico\nEn tant que professeur d’espagnol, mon plus grand défi est de faire faire leurs devoirs aux élèves. Ensuite, le second est de les empêcher d’écrire tout en français dans un traducteur en ligne, mais plutôt de l’utiliser à bon escient lorsqu’ils en ont le plus besoin.\nCependant, ce que j’ai appris jusqu’à présent, c’est que bien qu’ils soient censés être des natifs numériques, ils ne savent pas utiliser un tel outil efficacement. C’est comme avoir une voiture mais ne pas savoir comment la conduire correctement.\nJ’ai donc introduit Dico dans un cours où ils pouvaient chercher un certain nombre de mots pour accomplir une série de tâches. Moins ils l’utilisent, plus ils obtiennent de points. Cela les oblige à essayer de deviner ou à réaliser qu’ils pourraient ne pas avoir besoin de ce mot spécifique pour comprendre le document."
  },
  {
    "objectID": "posts/dico/dico-old.html#big-theta-de-dico",
    "href": "posts/dico/dico-old.html#big-theta-de-dico",
    "title": "Dico, première version",
    "section": "Big Theta de Dico",
    "text": "Big Theta de Dico\nÉtant un développeur adepte des “free tyer”, j’ai rapidement réalisé que même s’il est peu probable que mes élèves utilisent Dico assez pour atteindre la limite d’utilisation de l’API (1000 mots), cela pourrait arriver.\nDe plus, j’ai également réalisé que le coût algorithmique de Dico pourrait être exponentiel si chaque élève recherche n’importe quel mot. Pas performant du tout."
  },
  {
    "objectID": "posts/dico/dico-old.html#big-o-de-dico",
    "href": "posts/dico/dico-old.html#big-o-de-dico",
    "title": "Dico, première version",
    "section": "Big O de Dico",
    "text": "Big O de Dico\nLa solution que j’ai trouvée est basée en partie sur la linguistique et une stratégie de partage des coûts.\nJe sais en effet que nous, en tant que locuteurs, tendons à utiliser de moins en moins de vocabulaire de nos jours. J’ai donc pensé que si je pouvais stocker chaque mot la première fois qu’il a été recherché, cela rendrait le coût de l’algorithme linéaire au lieu d’exponentiel. Cela rendrait moins probable le dépassement de la limite de l’API puisque nous avons en moyenne environ 25 000 mots de vocabulaire. Enfin, cela pourrait améliorer la performance de recherche. Une fois qu’un mot a été recherché et stocké dans une base de données, il peut être accédé plus rapidement que s’il fallait le demander à l’API."
  },
  {
    "objectID": "posts/dico/dico-old.html#conclusion",
    "href": "posts/dico/dico-old.html#conclusion",
    "title": "Dico, première version",
    "section": "Conclusion",
    "text": "Conclusion\nEn somme, Dico est un dictionnaire automatique qui, malgré sa simplicité, aurait pu être vraiment coûteux si je n’avais pas trouvé une sorte d’optimisation. C’est un peu le revers de la médaille avec lequel j’ai dû travailler en évitant de trop solliciter l’API du dictionnaire."
  },
  {
    "objectID": "posts/first_notebook_model/goat_detector_training.html",
    "href": "posts/first_notebook_model/goat_detector_training.html",
    "title": "Mon premier modèle d’apprentissage automatique",
    "section": "",
    "text": "This notebook utilizes the fastai and fastbook libraries to train a machine learning model for image classification. The goal is to classify images as either featuring Messi or Cristiano Ronaldo, two renowned football players. ## Importing Necessary Libraries Import fastai and fastbook libraries essential for image loading, preparation, and machine learning model operations.\n\n\n\n%pip install -Uqq fastai fastbook Pillow nbdev\nimport fastbook\nfastbook.setup_book()\nfrom fastbook import *\n\nRequirement already satisfied: nbdev in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (2.3.13)\nRequirement already satisfied: ipywidgets&lt;=8.0.4 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from nbdev) (7.7.2)\nRequirement already satisfied: fastcore&gt;=1.5.27 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from nbdev) (1.5.29)\nRequirement already satisfied: execnb&gt;=0.1.4 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from nbdev) (0.1.5)\nRequirement already satisfied: astunparse in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from nbdev) (1.6.3)\nRequirement already satisfied: ghapi&gt;=1.0.3 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from nbdev) (1.0.4)\nRequirement already satisfied: watchdog in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from nbdev) (3.0.0)\nRequirement already satisfied: asttokens in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from nbdev) (2.4.1)\nRequirement already satisfied: PyYAML in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from nbdev) (6.0.1)\nRequirement already satisfied: ipython in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from execnb&gt;=0.1.4-&gt;nbdev) (8.20.0)\nRequirement already satisfied: pip in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from fastcore&gt;=1.5.27-&gt;nbdev) (23.3.2)\nRequirement already satisfied: packaging in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from fastcore&gt;=1.5.27-&gt;nbdev) (23.2)\nRequirement already satisfied: ipykernel&gt;=4.5.1 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from ipywidgets&lt;=8.0.4-&gt;nbdev) (6.28.0)\nRequirement already satisfied: ipython-genutils~=0.2.0 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from ipywidgets&lt;=8.0.4-&gt;nbdev) (0.2.0)\nRequirement already satisfied: traitlets&gt;=4.3.1 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from ipywidgets&lt;=8.0.4-&gt;nbdev) (5.14.1)\nRequirement already satisfied: widgetsnbextension~=3.6.0 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from ipywidgets&lt;=8.0.4-&gt;nbdev) (3.6.6)\nRequirement already satisfied: jupyterlab-widgets&lt;3,&gt;=1.0.0 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from ipywidgets&lt;=8.0.4-&gt;nbdev) (1.1.7)\nRequirement already satisfied: six&gt;=1.12.0 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from asttokens-&gt;nbdev) (1.16.0)\nRequirement already satisfied: wheel&lt;1.0,&gt;=0.23.0 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from astunparse-&gt;nbdev) (0.42.0)\nRequirement already satisfied: appnope in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from ipykernel&gt;=4.5.1-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (0.1.3)\nRequirement already satisfied: comm&gt;=0.1.1 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from ipykernel&gt;=4.5.1-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (0.2.1)\nRequirement already satisfied: debugpy&gt;=1.6.5 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from ipykernel&gt;=4.5.1-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (1.8.0)\nRequirement already satisfied: jupyter-client&gt;=6.1.12 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from ipykernel&gt;=4.5.1-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (8.6.0)\nRequirement already satisfied: jupyter-core!=5.0.*,&gt;=4.12 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from ipykernel&gt;=4.5.1-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (5.7.1)\nRequirement already satisfied: matplotlib-inline&gt;=0.1 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from ipykernel&gt;=4.5.1-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (0.1.6)\nRequirement already satisfied: nest-asyncio in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from ipykernel&gt;=4.5.1-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (1.5.8)\nRequirement already satisfied: psutil in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from ipykernel&gt;=4.5.1-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (5.9.7)\nRequirement already satisfied: pyzmq&gt;=24 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from ipykernel&gt;=4.5.1-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (25.1.2)\nRequirement already satisfied: tornado&gt;=6.1 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from ipykernel&gt;=4.5.1-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (6.3.3)\nRequirement already satisfied: decorator in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from ipython-&gt;execnb&gt;=0.1.4-&gt;nbdev) (5.1.1)\nRequirement already satisfied: jedi&gt;=0.16 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from ipython-&gt;execnb&gt;=0.1.4-&gt;nbdev) (0.19.1)\nRequirement already satisfied: prompt-toolkit&lt;3.1.0,&gt;=3.0.41 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from ipython-&gt;execnb&gt;=0.1.4-&gt;nbdev) (3.0.42)\nRequirement already satisfied: pygments&gt;=2.4.0 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from ipython-&gt;execnb&gt;=0.1.4-&gt;nbdev) (2.17.2)\nRequirement already satisfied: stack-data in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from ipython-&gt;execnb&gt;=0.1.4-&gt;nbdev) (0.6.2)\nRequirement already satisfied: exceptiongroup in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from ipython-&gt;execnb&gt;=0.1.4-&gt;nbdev) (1.2.0)\nRequirement already satisfied: pexpect&gt;4.3 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from ipython-&gt;execnb&gt;=0.1.4-&gt;nbdev) (4.8.0)\nRequirement already satisfied: notebook&gt;=4.4.1 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from widgetsnbextension~=3.6.0-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (7.0.6)\nRequirement already satisfied: parso&lt;0.9.0,&gt;=0.8.3 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from jedi&gt;=0.16-&gt;ipython-&gt;execnb&gt;=0.1.4-&gt;nbdev) (0.8.3)\nRequirement already satisfied: python-dateutil&gt;=2.8.2 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from jupyter-client&gt;=6.1.12-&gt;ipykernel&gt;=4.5.1-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (2.8.2)\nRequirement already satisfied: platformdirs&gt;=2.5 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from jupyter-core!=5.0.*,&gt;=4.12-&gt;ipykernel&gt;=4.5.1-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (4.1.0)\nRequirement already satisfied: jupyter-server&lt;3,&gt;=2.4.0 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (2.12.4)\nRequirement already satisfied: jupyterlab-server&lt;3,&gt;=2.22.1 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (2.25.2)\nRequirement already satisfied: jupyterlab&lt;5,&gt;=4.0.2 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (4.0.10)\nRequirement already satisfied: notebook-shim&lt;0.3,&gt;=0.2 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (0.2.3)\nRequirement already satisfied: ptyprocess&gt;=0.5 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from pexpect&gt;4.3-&gt;ipython-&gt;execnb&gt;=0.1.4-&gt;nbdev) (0.7.0)\nRequirement already satisfied: wcwidth in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from prompt-toolkit&lt;3.1.0,&gt;=3.0.41-&gt;ipython-&gt;execnb&gt;=0.1.4-&gt;nbdev) (0.2.13)\nRequirement already satisfied: executing&gt;=1.2.0 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from stack-data-&gt;ipython-&gt;execnb&gt;=0.1.4-&gt;nbdev) (2.0.1)\nRequirement already satisfied: pure-eval in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from stack-data-&gt;ipython-&gt;execnb&gt;=0.1.4-&gt;nbdev) (0.2.2)\nRequirement already satisfied: anyio&gt;=3.1.0 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from jupyter-server&lt;3,&gt;=2.4.0-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (4.2.0)\nRequirement already satisfied: argon2-cffi in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from jupyter-server&lt;3,&gt;=2.4.0-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (23.1.0)\nRequirement already satisfied: jinja2 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from jupyter-server&lt;3,&gt;=2.4.0-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (3.1.3)\nRequirement already satisfied: jupyter-events&gt;=0.9.0 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from jupyter-server&lt;3,&gt;=2.4.0-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (0.9.0)\nRequirement already satisfied: jupyter-server-terminals in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from jupyter-server&lt;3,&gt;=2.4.0-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (0.5.1)\nRequirement already satisfied: nbconvert&gt;=6.4.4 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from jupyter-server&lt;3,&gt;=2.4.0-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (7.14.1)\nRequirement already satisfied: nbformat&gt;=5.3.0 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from jupyter-server&lt;3,&gt;=2.4.0-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (5.9.2)\nRequirement already satisfied: overrides in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from jupyter-server&lt;3,&gt;=2.4.0-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (7.4.0)\nRequirement already satisfied: prometheus-client in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from jupyter-server&lt;3,&gt;=2.4.0-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (0.19.0)\nRequirement already satisfied: send2trash&gt;=1.8.2 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from jupyter-server&lt;3,&gt;=2.4.0-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (1.8.2)\nRequirement already satisfied: terminado&gt;=0.8.3 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from jupyter-server&lt;3,&gt;=2.4.0-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (0.18.0)\nRequirement already satisfied: websocket-client in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from jupyter-server&lt;3,&gt;=2.4.0-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (1.7.0)\nRequirement already satisfied: async-lru&gt;=1.0.0 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from jupyterlab&lt;5,&gt;=4.0.2-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (2.0.4)\nRequirement already satisfied: jupyter-lsp&gt;=2.0.0 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from jupyterlab&lt;5,&gt;=4.0.2-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (2.2.1)\nRequirement already satisfied: tomli in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from jupyterlab&lt;5,&gt;=4.0.2-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (2.0.1)\nRequirement already satisfied: babel&gt;=2.10 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from jupyterlab-server&lt;3,&gt;=2.22.1-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (2.14.0)\nRequirement already satisfied: json5&gt;=0.9.0 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from jupyterlab-server&lt;3,&gt;=2.22.1-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (0.9.14)\nRequirement already satisfied: jsonschema&gt;=4.18.0 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from jupyterlab-server&lt;3,&gt;=2.22.1-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (4.20.0)\nRequirement already satisfied: requests&gt;=2.31 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from jupyterlab-server&lt;3,&gt;=2.22.1-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (2.31.0)\nRequirement already satisfied: idna&gt;=2.8 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from anyio&gt;=3.1.0-&gt;jupyter-server&lt;3,&gt;=2.4.0-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (3.6)\nRequirement already satisfied: sniffio&gt;=1.1 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from anyio&gt;=3.1.0-&gt;jupyter-server&lt;3,&gt;=2.4.0-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (1.3.0)\nRequirement already satisfied: typing-extensions&gt;=4.1 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from anyio&gt;=3.1.0-&gt;jupyter-server&lt;3,&gt;=2.4.0-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (4.9.0)\nRequirement already satisfied: MarkupSafe&gt;=2.0 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from jinja2-&gt;jupyter-server&lt;3,&gt;=2.4.0-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (2.1.3)\nRequirement already satisfied: attrs&gt;=22.2.0 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from jsonschema&gt;=4.18.0-&gt;jupyterlab-server&lt;3,&gt;=2.22.1-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (23.2.0)\nRequirement already satisfied: jsonschema-specifications&gt;=2023.03.6 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from jsonschema&gt;=4.18.0-&gt;jupyterlab-server&lt;3,&gt;=2.22.1-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (2023.12.1)\nRequirement already satisfied: referencing&gt;=0.28.4 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from jsonschema&gt;=4.18.0-&gt;jupyterlab-server&lt;3,&gt;=2.22.1-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (0.32.1)\nRequirement already satisfied: rpds-py&gt;=0.7.1 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from jsonschema&gt;=4.18.0-&gt;jupyterlab-server&lt;3,&gt;=2.22.1-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (0.16.2)\nRequirement already satisfied: python-json-logger&gt;=2.0.4 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from jupyter-events&gt;=0.9.0-&gt;jupyter-server&lt;3,&gt;=2.4.0-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (2.0.7)\nRequirement already satisfied: rfc3339-validator in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from jupyter-events&gt;=0.9.0-&gt;jupyter-server&lt;3,&gt;=2.4.0-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (0.1.4)\nRequirement already satisfied: rfc3986-validator&gt;=0.1.1 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from jupyter-events&gt;=0.9.0-&gt;jupyter-server&lt;3,&gt;=2.4.0-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (0.1.1)\nRequirement already satisfied: beautifulsoup4 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from nbconvert&gt;=6.4.4-&gt;jupyter-server&lt;3,&gt;=2.4.0-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (4.12.2)\nRequirement already satisfied: bleach!=5.0.0 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from nbconvert&gt;=6.4.4-&gt;jupyter-server&lt;3,&gt;=2.4.0-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (6.1.0)\nRequirement already satisfied: defusedxml in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from nbconvert&gt;=6.4.4-&gt;jupyter-server&lt;3,&gt;=2.4.0-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (0.7.1)\nRequirement already satisfied: jupyterlab-pygments in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from nbconvert&gt;=6.4.4-&gt;jupyter-server&lt;3,&gt;=2.4.0-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (0.3.0)\nRequirement already satisfied: mistune&lt;4,&gt;=2.0.3 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from nbconvert&gt;=6.4.4-&gt;jupyter-server&lt;3,&gt;=2.4.0-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (3.0.2)\nRequirement already satisfied: nbclient&gt;=0.5.0 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from nbconvert&gt;=6.4.4-&gt;jupyter-server&lt;3,&gt;=2.4.0-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (0.8.0)\nRequirement already satisfied: pandocfilters&gt;=1.4.1 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from nbconvert&gt;=6.4.4-&gt;jupyter-server&lt;3,&gt;=2.4.0-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (1.5.0)\nRequirement already satisfied: tinycss2 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from nbconvert&gt;=6.4.4-&gt;jupyter-server&lt;3,&gt;=2.4.0-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (1.2.1)\nRequirement already satisfied: fastjsonschema in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from nbformat&gt;=5.3.0-&gt;jupyter-server&lt;3,&gt;=2.4.0-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (2.19.1)\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from requests&gt;=2.31-&gt;jupyterlab-server&lt;3,&gt;=2.22.1-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (3.3.2)\nRequirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from requests&gt;=2.31-&gt;jupyterlab-server&lt;3,&gt;=2.22.1-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (2.1.0)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from requests&gt;=2.31-&gt;jupyterlab-server&lt;3,&gt;=2.22.1-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (2023.11.17)\nRequirement already satisfied: argon2-cffi-bindings in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from argon2-cffi-&gt;jupyter-server&lt;3,&gt;=2.4.0-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (21.2.0)\nRequirement already satisfied: webencodings in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from bleach!=5.0.0-&gt;nbconvert&gt;=6.4.4-&gt;jupyter-server&lt;3,&gt;=2.4.0-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (0.5.1)\nRequirement already satisfied: fqdn in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from jsonschema[format-nongpl]&gt;=4.18.0-&gt;jupyter-events&gt;=0.9.0-&gt;jupyter-server&lt;3,&gt;=2.4.0-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (1.5.1)\nRequirement already satisfied: isoduration in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from jsonschema[format-nongpl]&gt;=4.18.0-&gt;jupyter-events&gt;=0.9.0-&gt;jupyter-server&lt;3,&gt;=2.4.0-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (20.11.0)\nRequirement already satisfied: jsonpointer&gt;1.13 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from jsonschema[format-nongpl]&gt;=4.18.0-&gt;jupyter-events&gt;=0.9.0-&gt;jupyter-server&lt;3,&gt;=2.4.0-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (2.4)\nRequirement already satisfied: uri-template in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from jsonschema[format-nongpl]&gt;=4.18.0-&gt;jupyter-events&gt;=0.9.0-&gt;jupyter-server&lt;3,&gt;=2.4.0-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (1.3.0)\nRequirement already satisfied: webcolors&gt;=1.11 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from jsonschema[format-nongpl]&gt;=4.18.0-&gt;jupyter-events&gt;=0.9.0-&gt;jupyter-server&lt;3,&gt;=2.4.0-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (1.13)\nRequirement already satisfied: cffi&gt;=1.0.1 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from argon2-cffi-bindings-&gt;argon2-cffi-&gt;jupyter-server&lt;3,&gt;=2.4.0-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (1.16.0)\nRequirement already satisfied: soupsieve&gt;1.2 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from beautifulsoup4-&gt;nbconvert&gt;=6.4.4-&gt;jupyter-server&lt;3,&gt;=2.4.0-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (2.5)\nRequirement already satisfied: pycparser in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from cffi&gt;=1.0.1-&gt;argon2-cffi-bindings-&gt;argon2-cffi-&gt;jupyter-server&lt;3,&gt;=2.4.0-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (2.21)\nRequirement already satisfied: arrow&gt;=0.15.0 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from isoduration-&gt;jsonschema[format-nongpl]&gt;=4.18.0-&gt;jupyter-events&gt;=0.9.0-&gt;jupyter-server&lt;3,&gt;=2.4.0-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (1.3.0)\nRequirement already satisfied: types-python-dateutil&gt;=2.8.10 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from arrow&gt;=0.15.0-&gt;isoduration-&gt;jsonschema[format-nongpl]&gt;=4.18.0-&gt;jupyter-events&gt;=0.9.0-&gt;jupyter-server&lt;3,&gt;=2.4.0-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.6.0-&gt;ipywidgets&lt;=8.0.4-&gt;nbdev) (2.8.19.20240106)\nRequirement already satisfied: gradio==3.47.1 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (3.47.1)\nRequirement already satisfied: aiofiles&lt;24.0,&gt;=22.0 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from gradio==3.47.1) (23.2.1)\nRequirement already satisfied: altair&lt;6.0,&gt;=4.2.0 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from gradio==3.47.1) (5.2.0)\nRequirement already satisfied: fastapi in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from gradio==3.47.1) (0.109.0)\nRequirement already satisfied: ffmpy in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from gradio==3.47.1) (0.3.1)\nRequirement already satisfied: gradio-client==0.6.0 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from gradio==3.47.1) (0.6.0)\nRequirement already satisfied: httpx in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from gradio==3.47.1) (0.26.0)\nRequirement already satisfied: huggingface-hub&gt;=0.14.0 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from gradio==3.47.1) (0.20.2)\nRequirement already satisfied: importlib-resources&lt;7.0,&gt;=1.3 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from gradio==3.47.1) (6.1.1)\nRequirement already satisfied: jinja2&lt;4.0 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from gradio==3.47.1) (3.1.3)\nRequirement already satisfied: markupsafe~=2.0 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from gradio==3.47.1) (2.1.3)\nRequirement already satisfied: matplotlib~=3.0 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from gradio==3.47.1) (3.8.2)\nRequirement already satisfied: numpy~=1.0 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from gradio==3.47.1) (1.26.3)\nRequirement already satisfied: orjson~=3.0 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from gradio==3.47.1) (3.9.10)\nRequirement already satisfied: packaging in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from gradio==3.47.1) (23.2)\nRequirement already satisfied: pandas&lt;3.0,&gt;=1.0 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from gradio==3.47.1) (2.1.4)\nRequirement already satisfied: pillow&lt;11.0,&gt;=8.0 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from gradio==3.47.1) (10.2.0)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,&lt;3.0.0,&gt;=1.7.4 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from gradio==3.47.1) (2.0.3)\nRequirement already satisfied: pydub in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from gradio==3.47.1) (0.25.1)\nRequirement already satisfied: python-multipart in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from gradio==3.47.1) (0.0.6)\nRequirement already satisfied: pyyaml&lt;7.0,&gt;=5.0 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from gradio==3.47.1) (6.0.1)\nRequirement already satisfied: requests~=2.0 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from gradio==3.47.1) (2.31.0)\nRequirement already satisfied: semantic-version~=2.0 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from gradio==3.47.1) (2.10.0)\nRequirement already satisfied: typing-extensions~=4.0 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from gradio==3.47.1) (4.9.0)\nRequirement already satisfied: uvicorn&gt;=0.14.0 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from gradio==3.47.1) (0.25.0)\nRequirement already satisfied: websockets&lt;12.0,&gt;=10.0 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from gradio==3.47.1) (11.0.3)\nRequirement already satisfied: fsspec in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from gradio-client==0.6.0-&gt;gradio==3.47.1) (2023.10.0)\nRequirement already satisfied: jsonschema&gt;=3.0 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from altair&lt;6.0,&gt;=4.2.0-&gt;gradio==3.47.1) (4.20.0)\nRequirement already satisfied: toolz in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from altair&lt;6.0,&gt;=4.2.0-&gt;gradio==3.47.1) (0.12.0)\nRequirement already satisfied: filelock in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from huggingface-hub&gt;=0.14.0-&gt;gradio==3.47.1) (3.13.1)\nRequirement already satisfied: tqdm&gt;=4.42.1 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from huggingface-hub&gt;=0.14.0-&gt;gradio==3.47.1) (4.66.1)\nRequirement already satisfied: contourpy&gt;=1.0.1 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from matplotlib~=3.0-&gt;gradio==3.47.1) (1.2.0)\nRequirement already satisfied: cycler&gt;=0.10 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from matplotlib~=3.0-&gt;gradio==3.47.1) (0.12.1)\nRequirement already satisfied: fonttools&gt;=4.22.0 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from matplotlib~=3.0-&gt;gradio==3.47.1) (4.47.2)\nRequirement already satisfied: kiwisolver&gt;=1.3.1 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from matplotlib~=3.0-&gt;gradio==3.47.1) (1.4.5)\nRequirement already satisfied: pyparsing&gt;=2.3.1 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from matplotlib~=3.0-&gt;gradio==3.47.1) (3.1.1)\nRequirement already satisfied: python-dateutil&gt;=2.7 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from matplotlib~=3.0-&gt;gradio==3.47.1) (2.8.2)\nRequirement already satisfied: pytz&gt;=2020.1 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from pandas&lt;3.0,&gt;=1.0-&gt;gradio==3.47.1) (2023.3.post1)\nRequirement already satisfied: tzdata&gt;=2022.1 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from pandas&lt;3.0,&gt;=1.0-&gt;gradio==3.47.1) (2023.4)\nRequirement already satisfied: annotated-types&gt;=0.4.0 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,&lt;3.0.0,&gt;=1.7.4-&gt;gradio==3.47.1) (0.6.0)\nRequirement already satisfied: pydantic-core==2.3.0 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,&lt;3.0.0,&gt;=1.7.4-&gt;gradio==3.47.1) (2.3.0)\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from requests~=2.0-&gt;gradio==3.47.1) (3.3.2)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from requests~=2.0-&gt;gradio==3.47.1) (3.6)\nRequirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from requests~=2.0-&gt;gradio==3.47.1) (2.1.0)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from requests~=2.0-&gt;gradio==3.47.1) (2023.11.17)\nRequirement already satisfied: click&gt;=7.0 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from uvicorn&gt;=0.14.0-&gt;gradio==3.47.1) (8.1.7)\nRequirement already satisfied: h11&gt;=0.8 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from uvicorn&gt;=0.14.0-&gt;gradio==3.47.1) (0.14.0)\nRequirement already satisfied: starlette&lt;0.36.0,&gt;=0.35.0 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from fastapi-&gt;gradio==3.47.1) (0.35.1)\nRequirement already satisfied: anyio in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from httpx-&gt;gradio==3.47.1) (4.2.0)\nRequirement already satisfied: httpcore==1.* in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from httpx-&gt;gradio==3.47.1) (1.0.2)\nRequirement already satisfied: sniffio in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from httpx-&gt;gradio==3.47.1) (1.3.0)\nRequirement already satisfied: attrs&gt;=22.2.0 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from jsonschema&gt;=3.0-&gt;altair&lt;6.0,&gt;=4.2.0-&gt;gradio==3.47.1) (23.2.0)\nRequirement already satisfied: jsonschema-specifications&gt;=2023.03.6 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from jsonschema&gt;=3.0-&gt;altair&lt;6.0,&gt;=4.2.0-&gt;gradio==3.47.1) (2023.12.1)\nRequirement already satisfied: referencing&gt;=0.28.4 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from jsonschema&gt;=3.0-&gt;altair&lt;6.0,&gt;=4.2.0-&gt;gradio==3.47.1) (0.32.1)\nRequirement already satisfied: rpds-py&gt;=0.7.1 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from jsonschema&gt;=3.0-&gt;altair&lt;6.0,&gt;=4.2.0-&gt;gradio==3.47.1) (0.16.2)\nRequirement already satisfied: six&gt;=1.5 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from python-dateutil&gt;=2.7-&gt;matplotlib~=3.0-&gt;gradio==3.47.1) (1.16.0)\nRequirement already satisfied: exceptiongroup&gt;=1.0.2 in /Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages (from anyio-&gt;httpx-&gt;gradio==3.47.1) (1.2.0)\n\n\n\nFigure 1\n\n\n\n\n\nLoad the dataset containing images of Messi and Cristiano Ronaldo. This step includes preprocessing the images to make them suitable for training the model.\n\nfrom fastcore.all import *\nfrom fastai.vision.all import *\nfrom PIL import Image\n\ndef search_images(term, max_images=30):\n    \"term : (string )name of the search target\"\n    print(f\"Searching for '{term}'\")\n    return search_images_ddg(term, max_images)\n\n\n\nurls = search_images('Cristiano Ronaldo photos', max_images=1)\nurls[0]\n\nSearching for 'Cristiano Ronaldo photos'\n\n\n'http://www.fotolip.com/wp-content/uploads/2016/05/Cristiano-Ronaldo-1.jpg'\n\n\n\nfrom fastdownload import download_url\ndest = 'cristiano.jpg'\ndownload_url(urls[0], dest, show_progress=False)\n\nim = Image.open(dest)\nim.to_thumb(256,256)\n\n\n\n\n\n\n\n\n\nmessi_dest = 'messi.jpg'\nmessi_image_url = search_images('Lionel Messi photos', max_images=1)\nmessi_image_url\n\nSearching for 'Lionel Messi photos'\n\n\n(#1) ['https://wallpapercave.com/wp/wp2043344.jpg']\n\n\n\ndownload_url(messi_image_url[0], messi_dest, show_progress=False)\nim_messi = Image.open(messi_dest)\nim_messi.to_thumb(256,256)\n\n\n\n\n\n\n\n\n\nsearches = 'Cristiano Ronaldo','Lionel Messi'\n\npath = Path('images')\nfrom time import sleep\n\nfor o in searches:\n    dest = (path/o)\n    print(dest)\n    dest.mkdir(exist_ok=True, parents=True)\n    download_images(dest, urls=search_images(f'{o} photo'))\n    sleep(10)  # Pause between searches to avoid over-loading server\n    resize_images(path/o, max_size=400, dest=path/o)\n\nimages/Cristiano Ronaldo\nSearching for 'Cristiano Ronaldo photo'\nimages/Lionel Messi\nSearching for 'Lionel Messi photo'\n\n\n/Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages/PIL/Image.py:981: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n\n\n\n# Check if any image is broken and delete it\nfailed = verify_images(get_image_files(path))\nfailed.map(Path.unlink)\nlen(failed)\n\n0\n\n\n\n\n\nSetup of the pretrained model for fine-tuning. This includes specifying model parameters and configuring the learning environment.\n\ndls = DataBlock(\n    blocks=(ImageBlock, CategoryBlock),\n    get_items=get_image_files,\n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=[Resize(192, method='squish')]\n).dataloaders(path, bs=32)\n\ndls.show_batch(max_n=6)\n\n\n\n\n\n\n\n\n\n\n\nFine-tuning the pretrained model on our dataset. This step involves training the model to classify images as either Messi or Cristiano Ronaldo accurately.\n\nlearn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(3)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n1.065711\n0.397649\n0.196078\n00:02\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.476915\n0.178397\n0.058824\n00:02\n\n\n1\n0.365285\n0.163348\n0.058824\n00:02\n\n\n2\n0.277333\n0.129455\n0.058824\n00:02\n\n\n\n\n\n\nresults = learn.show_results()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAssess the performance of the trained model on test data to ensure accurate classification.\n\nis_goat,_,probs = learn.predict(PILImage.create('cristiano.jpg'))\nprint(f\"Who is it?: {is_goat}.\")\nprint(f\"Probability it's the GOAT: {probs[0]:.4f}\")\n\n\n\n\n\n\n\n\nIs it the GOAT?: Cristiano Ronaldo.\nProbability it's the GOAT: 0.9999\n\n\n\nis_goat,_,probs = learn.predict(PILImage.create('messi.jpg'))\nprint(f\"Who is it?: {is_goat}.\")\nprint(f\"Probability it's the GOAT: {probs[0]:.4f} 🙃\")  # Picking the probability it's Ronaldo when it's Messi tells the joke\n\n\n\n\n\n\n\n\nWho is it?: Lionel Messi.\nProbability it's the GOAT: 0.0002 🙃\n\n\n\n# Exports the model as a pickel file that may later be loaded, regardless of all the code that have served to train it.\n# Have a look on the goat_detector_inference.ipynb file to see how it's done \nlearn.export()\n\n\n\n\nSummary of the training process and results. The trained model is now capable of classifying images between Messi and Cristiano Ronaldo with a certain accuracy."
  },
  {
    "objectID": "posts/first_notebook_model/goat_detector_training.html#loading-and-preparing-images",
    "href": "posts/first_notebook_model/goat_detector_training.html#loading-and-preparing-images",
    "title": "Mon premier modèle d’apprentissage automatique",
    "section": "",
    "text": "Load the dataset containing images of Messi and Cristiano Ronaldo. This step includes preprocessing the images to make them suitable for training the model.\n\nfrom fastcore.all import *\nfrom fastai.vision.all import *\nfrom PIL import Image\n\ndef search_images(term, max_images=30):\n    \"term : (string )name of the search target\"\n    print(f\"Searching for '{term}'\")\n    return search_images_ddg(term, max_images)\n\n\n\nurls = search_images('Cristiano Ronaldo photos', max_images=1)\nurls[0]\n\nSearching for 'Cristiano Ronaldo photos'\n\n\n'http://www.fotolip.com/wp-content/uploads/2016/05/Cristiano-Ronaldo-1.jpg'\n\n\n\nfrom fastdownload import download_url\ndest = 'cristiano.jpg'\ndownload_url(urls[0], dest, show_progress=False)\n\nim = Image.open(dest)\nim.to_thumb(256,256)\n\n\n\n\n\n\n\n\n\nmessi_dest = 'messi.jpg'\nmessi_image_url = search_images('Lionel Messi photos', max_images=1)\nmessi_image_url\n\nSearching for 'Lionel Messi photos'\n\n\n(#1) ['https://wallpapercave.com/wp/wp2043344.jpg']\n\n\n\ndownload_url(messi_image_url[0], messi_dest, show_progress=False)\nim_messi = Image.open(messi_dest)\nim_messi.to_thumb(256,256)\n\n\n\n\n\n\n\n\n\nsearches = 'Cristiano Ronaldo','Lionel Messi'\n\npath = Path('images')\nfrom time import sleep\n\nfor o in searches:\n    dest = (path/o)\n    print(dest)\n    dest.mkdir(exist_ok=True, parents=True)\n    download_images(dest, urls=search_images(f'{o} photo'))\n    sleep(10)  # Pause between searches to avoid over-loading server\n    resize_images(path/o, max_size=400, dest=path/o)\n\nimages/Cristiano Ronaldo\nSearching for 'Cristiano Ronaldo photo'\nimages/Lionel Messi\nSearching for 'Lionel Messi photo'\n\n\n/Users/jasonsuarez/anaconda3/envs/pydata-book/lib/python3.10/site-packages/PIL/Image.py:981: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n\n\n\n# Check if any image is broken and delete it\nfailed = verify_images(get_image_files(path))\nfailed.map(Path.unlink)\nlen(failed)\n\n0"
  },
  {
    "objectID": "posts/first_notebook_model/goat_detector_training.html#preparing-for-model-training",
    "href": "posts/first_notebook_model/goat_detector_training.html#preparing-for-model-training",
    "title": "Mon premier modèle d’apprentissage automatique",
    "section": "",
    "text": "Setup of the pretrained model for fine-tuning. This includes specifying model parameters and configuring the learning environment.\n\ndls = DataBlock(\n    blocks=(ImageBlock, CategoryBlock),\n    get_items=get_image_files,\n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=[Resize(192, method='squish')]\n).dataloaders(path, bs=32)\n\ndls.show_batch(max_n=6)"
  },
  {
    "objectID": "posts/first_notebook_model/goat_detector_training.html#training-the-model",
    "href": "posts/first_notebook_model/goat_detector_training.html#training-the-model",
    "title": "Mon premier modèle d’apprentissage automatique",
    "section": "",
    "text": "Fine-tuning the pretrained model on our dataset. This step involves training the model to classify images as either Messi or Cristiano Ronaldo accurately.\n\nlearn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(3)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n1.065711\n0.397649\n0.196078\n00:02\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.476915\n0.178397\n0.058824\n00:02\n\n\n1\n0.365285\n0.163348\n0.058824\n00:02\n\n\n2\n0.277333\n0.129455\n0.058824\n00:02\n\n\n\n\n\n\nresults = learn.show_results()"
  },
  {
    "objectID": "posts/first_notebook_model/goat_detector_training.html#evaluating-the-model",
    "href": "posts/first_notebook_model/goat_detector_training.html#evaluating-the-model",
    "title": "Mon premier modèle d’apprentissage automatique",
    "section": "",
    "text": "Assess the performance of the trained model on test data to ensure accurate classification.\n\nis_goat,_,probs = learn.predict(PILImage.create('cristiano.jpg'))\nprint(f\"Who is it?: {is_goat}.\")\nprint(f\"Probability it's the GOAT: {probs[0]:.4f}\")\n\n\n\n\n\n\n\n\nIs it the GOAT?: Cristiano Ronaldo.\nProbability it's the GOAT: 0.9999\n\n\n\nis_goat,_,probs = learn.predict(PILImage.create('messi.jpg'))\nprint(f\"Who is it?: {is_goat}.\")\nprint(f\"Probability it's the GOAT: {probs[0]:.4f} 🙃\")  # Picking the probability it's Ronaldo when it's Messi tells the joke\n\n\n\n\n\n\n\n\nWho is it?: Lionel Messi.\nProbability it's the GOAT: 0.0002 🙃\n\n\n\n# Exports the model as a pickel file that may later be loaded, regardless of all the code that have served to train it.\n# Have a look on the goat_detector_inference.ipynb file to see how it's done \nlearn.export()"
  },
  {
    "objectID": "posts/first_notebook_model/goat_detector_training.html#conclusion",
    "href": "posts/first_notebook_model/goat_detector_training.html#conclusion",
    "title": "Mon premier modèle d’apprentissage automatique",
    "section": "",
    "text": "Summary of the training process and results. The trained model is now capable of classifying images between Messi and Cristiano Ronaldo with a certain accuracy."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "A propos",
    "section": "",
    "text": "Chez Education 2.0, nous croyons en une vision d’apprentissage qui transcende les frontières traditionnelles. Notre mission est d’explorer les horizons de l’éducation, de repousser les limites de l’apprentissage, et d’inspirer une nouvelle génération d’apprenants et d’éducateurs.\nMon propre parcours éducatif est le moteur de ce blog. Originaire de la République Dominicaine, j’ai fait de Paris ma maison. En tant que professeur d’espagnol, j’ai eu le privilège d’enseigner et de voir les lumières de la compréhension s’allumer dans les yeux de mes élèves. Mais j’ai toujours été un éternel apprenant, avide de découvrir comment fonctionne le cerveau humain et comment l’IA peut améliorer nos vies.\nEducation 2.0 est né de cette passion pour l’éducation et l’innovation. Ici, nous explorons un éventail d’idées, des neurosciences cognitives aux projets d’IA en passant par les défis de l’apprentissage moderne. Nous partageons notre propre voyage à travers le développement de projets, des initiatives conçues pour repousser les frontières de l’apprentissage personnalisé et de l’optimisation éducative."
  }
]